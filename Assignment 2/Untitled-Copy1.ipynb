{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aashish Adhikari\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "try:\n",
    "   import _pickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# This is a class for a LinearTransform layer which takes an input \n",
    "# weight matrix W and computes W x as the forward step\n",
    "\n",
    "\n",
    "\n",
    "class LinearTransform(object):\n",
    "\n",
    "    def __init__(self, W, b):\n",
    "\t# DEFINE __init function\n",
    "\n",
    "    def forward(self, x):\n",
    "\t# DEFINE forward function\n",
    "\n",
    "    def backward(\n",
    "        self, \n",
    "        grad_output, \n",
    "        learning_rate=0.0, \n",
    "        momentum=0.0, \n",
    "        l2_penalty=0.0,\n",
    "    ):\n",
    "\t# DEFINE backward function\n",
    "# ADD other operations in LinearTransform if needed\n",
    "\n",
    "\n",
    "\n",
    "# This is a class for a ReLU layer max(x,0)\n",
    "\n",
    "\n",
    "\n",
    "class ReLU(object):\n",
    "\n",
    "    def forward(self, x):\n",
    "\t# DEFINE forward function\n",
    "\n",
    "    def backward(\n",
    "        self, \n",
    "        grad_output, \n",
    "        learning_rate=0.0, \n",
    "        momentum=0.0, \n",
    "        l2_penalty=0.0,\n",
    "    ):\n",
    "    # DEFINE backward function\n",
    "# ADD other operations in ReLU if needed\n",
    "\n",
    "\n",
    "\n",
    "# This is a class for a sigmoid layer followed by a cross entropy layer, the reason \n",
    "# this is put into a single layer is because it has a simple gradient form\n",
    "\n",
    "\n",
    "\n",
    "class SigmoidCrossEntropy(object):\n",
    "\tdef forward(self, x):\n",
    "\t\t# DEFINE forward function\n",
    "\tdef backward(\n",
    "\t    self, \n",
    "\t    grad_output, \n",
    "\t\tlearning_rate=0.0,\n",
    "\t\tmomentum=0.0,\n",
    "\t\tl2_penalty=0.0\n",
    "\t):\n",
    "\t\t# DEFINE backward function\n",
    "# ADD other operations and data entries in SigmoidCrossEntropy if needed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This is a class for the Multilayer perceptron\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MLP(object):\n",
    "\n",
    "    def __init__(self, input_dims, hidden_units):\n",
    "    # INSERT CODE for initializing the network\n",
    "\n",
    "    def train(\n",
    "        self, \n",
    "        x_batch, \n",
    "        y_batch, \n",
    "        learning_rate, \n",
    "        momentum,\n",
    "        l2_penalty,\n",
    "    ):\n",
    "\t# INSERT CODE for training the network\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "\t# INSERT CODE for testing the network\n",
    "# ADD other operations and data entries in MLP if needed\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if sys.version_info[0] < 3:\n",
    "        data = pickle.load(open('cifar_2class_py2.p', 'rb'))\n",
    "\telse:\n",
    "\t    data = pickle.load(open('cifar_2class_py2.p', 'rb'), encoding='bytes')\n",
    "\n",
    "    train_x = data['train_data']\n",
    "    train_y = data['train_labels']\n",
    "    test_x = data['test_data']\n",
    "    test_y = data['test_labels']\n",
    "\t\n",
    "    num_examples, input_dims = train_x.shape\n",
    "\t# INSERT YOUR CODE HERE\n",
    "\t# YOU CAN CHANGE num_epochs AND num_batches TO YOUR DESIRED VALUES\n",
    "\tnum_epochs = 10\n",
    "\tnum_batches = 1000\n",
    "    mlp = MLP(input_dims, hidden_units)\n",
    "\n",
    "    for epoch in xrange(num_epochs):\n",
    "\n",
    "\t# INSERT YOUR CODE FOR EACH EPOCH HERE\n",
    "\n",
    "        for b in xrange(num_batches):\n",
    "\t\t\ttotal_loss = 0.0\n",
    "\t\t\t# INSERT YOUR CODE FOR EACH MINI_BATCH HERE\n",
    "\t\t\t# MAKE SURE TO UPDATE total_loss\n",
    "            print(\n",
    "                '\\r[Epoch {}, mb {}]    Avg.Loss = {:.3f}'.format(\n",
    "                    epoch + 1,\n",
    "                    b + 1,\n",
    "                    total_loss,\n",
    "                ),\n",
    "                end='',\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\t\t# INSERT YOUR CODE AFTER ALL MINI_BATCHES HERE\n",
    "\t\t# MAKE SURE TO COMPUTE train_loss, train_accuracy, test_loss, test_accuracy\n",
    "        print()\n",
    "        print('    Train Loss: {:.3f}    Train Acc.: {:.2f}%'.format(\n",
    "            train_loss,\n",
    "            100. * train_accuracy,\n",
    "        ))\n",
    "        print('    Test Loss:  {:.3f}    Test Acc.:  {:.2f}%'.format(\n",
    "            test_loss,\n",
    "            100. * test_accuracy,\n",
    "        ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
